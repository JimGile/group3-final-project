{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_relevant_data (url, keywords):\n",
    "    try:\n",
    "        #Fetch page Content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        #Extract text and search keywords\n",
    "        relevant_data = []\n",
    "        for element in soup.find_all(['p', 'h1', 'h2', 'h3', 'a']):\n",
    "            text_content = element.get_text(strip=True)\n",
    "            if any(keyword.lower() in text_content.lower() for keyword in keywords):\n",
    "                relevant_data.append(text_content)\n",
    "\n",
    "        #Return relevant selections of text\n",
    "        if relevant_data:\n",
    "            return relevant_data\n",
    "        else:\n",
    "            return \"No relevant data found for the specified keywords.\"\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occured: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "url = \"https://www.denvergov.org/Government/Agencies-Departments-Offices/Agencies-Departments-Offices-Directory/Denver-City-Council/Council-Members-Websites-Info/District-4\"\n",
    "keywords = [\"budget\", \"housing\", \"public safety\"]\n",
    "print(fetch_relevant_data(url, keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_display_summaries_with_links(topics: str):\n",
    "    url = \"https://www.denvergov.org/Government/Agencies-Departments-Offices/Agencies-Departments-Offices-Directory/Denver-City-Council/Council-Members-Websites-Info/District-4\"\n",
    "    keywords = [topic.strip() for topic in topics.split(',')]\n",
    "    try:\n",
    "        # Fetch and parse the page content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find relevant sections and generate summaries\n",
    "        relevant_articles = {}\n",
    "        for keyword in keywords:\n",
    "            relevant_articles[keyword] = []\n",
    "            for element in soup.find_all(['p', 'h1', 'h2', 'h3', 'a']):\n",
    "                if keyword.lower() in element.get_text(strip=True).lower():\n",
    "                    # Capture the parent section for full context\n",
    "                    section = element.find_parent()\n",
    "                    full_text = section.get_text(strip=True, separator=\"\\n\") if section else element.get_text(strip=True)\n",
    "                    \n",
    "                    # Generate a short summary (first 1-2 sentences)\n",
    "                    summary = '. '.join(full_text.split('. ')[:2]) + '...'\n",
    "                    \n",
    "                    # Add link if it's a URL element\n",
    "                    link = url if not element.name == 'a' else element.get('href', url)\n",
    "                    \n",
    "                    # Avoid duplicates\n",
    "                    if summary not in [item['summary'] for item in relevant_articles[keyword]]:\n",
    "                        relevant_articles[keyword].append({'summary': summary, 'link': link})\n",
    "        \n",
    "        # Format the output with summaries and links\n",
    "        display_output = \"### Summaries with Links to Full Articles:\\n\\n\"\n",
    "        for keyword, articles in relevant_articles.items():\n",
    "            display_output += f\"**Keyword: {keyword.capitalize()}**\\n\\n\"\n",
    "            for i, article in enumerate(articles, 1):\n",
    "                display_output += f\"{i}. {article['summary']} \"\n",
    "                display_output += f\"[Read More]({article['link']})\\n\\n\"\n",
    "                display_output += \"---\\n\"  # Separator between summaries\n",
    "            \n",
    "            if not articles:\n",
    "                display_output += f\"No articles found for **{keyword}**.\\n\\n\"\n",
    "\n",
    "        return display_output\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fetch_and_display_summaries_with_links(\"Police, Homeless\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "def fetch_and_display_search_results(base_url, keywords):\n",
    "    def get_relevant_content(search_url):\n",
    "        # Make a search request to the search URL\n",
    "        search_response = requests.get(search_url)\n",
    "        search_response.raise_for_status()\n",
    "        search_soup = BeautifulSoup(search_response.text, 'html.parser')\n",
    "        \n",
    "        # Extract relevant sections\n",
    "        relevant_articles = []\n",
    "        for element in search_soup.find_all(['p', 'h1', 'h2', 'h3', 'a']):\n",
    "            text_content = element.get_text(strip=True)\n",
    "            # Capture the parent section for full context\n",
    "            section = element.find_parent()\n",
    "            full_text = section.get_text(strip=True, separator=\"\\n\") if section else text_content\n",
    "            \n",
    "            # Generate a short summary (first 1-2 sentences)\n",
    "            summary = '. '.join(full_text.split('. ')[:2]) + '...'\n",
    "            # Link from the element or the main search URL\n",
    "            link = search_url if not element.name == 'a' else element.get('href', search_url)\n",
    "            \n",
    "            # Avoid duplicates\n",
    "            if summary not in [item['summary'] for item in relevant_articles]:\n",
    "                relevant_articles.append({'summary': summary, 'link': link})\n",
    "        \n",
    "        return relevant_articles\n",
    "    \n",
    "    # Format the output with summaries and links\n",
    "    display_output = \"### Summaries with Links to Search Results:\\n\\n\"\n",
    "    for keyword in keywords:\n",
    "        # Encode the keyword and create the complete search URL\n",
    "        encoded_keyword = urllib.parse.quote(keyword)\n",
    "        search_url = (\n",
    "            f\"{base_url}?keyword={encoded_keyword}&dlv_OC%20CL%20Public%20Landing%20Page%203%20Column=(keyword={encoded_keyword})\"\n",
    "        )\n",
    "        \n",
    "        display_output += f\"**Keyword: {keyword.capitalize()}**\\n\\n\"\n",
    "        articles = get_relevant_content(search_url)\n",
    "        \n",
    "        for i, article in enumerate(articles, 1):\n",
    "            display_output += f\"{i}. {article['summary']} \"\n",
    "            display_output += f\"[Read More]({article['link']})\\n\\n\"\n",
    "            display_output += \"---\\n\"  # Separator between summaries\n",
    "        \n",
    "        if not articles:\n",
    "            display_output += f\"No articles found for **{keyword}**.\\n\\n\"\n",
    "\n",
    "    return display_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example with keywords\n",
    "base_url = \"https://www.denvergov.org/Government/Agencies-Departments-Offices/Agencies-Departments-Offices-Directory\"\n",
    "keywords = [\"Police\"]\n",
    "print(fetch_and_display_search_results(base_url, keywords))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
