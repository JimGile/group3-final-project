{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model to use\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the model to use\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"\"\"I want information on getting a compost bin. I have submitted case number: 9578014.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the individual chains that make up each step of the complex workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the sentiment_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sentiment prompt that returns the given email and a sentiment response\n",
    "sentiment_prompt = PromptTemplate(\n",
    "    input_variables=[\"email\"],\n",
    "    output_key=\"sentiment\",\n",
    "    template=\"\"\"\n",
    "    Given the following email text:\n",
    "    {email}\n",
    "\n",
    "    Please provide a sentiment analysis with a response value of 'Negative', 'Neutral', or 'Positive'.\n",
    "\n",
    "    Format:\n",
    "    <your sentiment here>\n",
    "    \"\"\"\n",
    ")\n",
    "sentiment_chain = LLMChain(llm=llm, prompt=sentiment_prompt, output_key=\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentiment: Neutral'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the sentiment chain\n",
    "result_1 = sentiment_chain.run(email=email)\n",
    "result_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the topic_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the topics and their descriptions\n",
    "topics_dict = {\n",
    "    'Homeless': 'words similar to homeless, shelter,encampment',\n",
    "    'Graffiti': 'words similar to graffiti, paint, tagging',\n",
    "    'Pothole': 'words similar to pothole, holes',\n",
    "    'Animal': 'words similar to animal, pest, pets, barking',\n",
    "    'Vegitation': 'words similar to weeds, trees, limbs, overgrown',\n",
    "    'Neighborhood': 'words similar to HOA, RNO, sidewalk, fence',\n",
    "    'Snow Removal': 'words similar to snow, ice, plows',\n",
    "    'Vehicle': 'words similar to vehicle, car, motorcycle, automobile',\n",
    "    'Parking': 'words similar to parking',\n",
    "    'Police': 'words similar to police, gang, loud, drugs, crime',\n",
    "    'Fireworks': 'words similar to fireworks',\n",
    "    'Dumping': 'words similar to dumping',\n",
    "    'Trash': 'words similar to trash, garbage, compost, recycling',\n",
    "    'Housing': 'words similar to rent, rental, apartments, housing',\n",
    "    'Policy': 'words similar to policy, tax, taxes, mayor, council, councilwoman, councilman, environmental, environment, rezoning, rezone, government, politics',\n",
    "    'Street Racing': 'words similar to racing',\n",
    "    'Transit': 'words similar to transit, traffic, pedestrian, intersection, bicycle, bike, speed, pavement',\n",
    "    'Parks': 'words similar to park, playground, trails, pool, gym, medians',\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a string\n",
    "topic_descriptions = \"\\n\".join([f\"{key}: {desc}\" for key, desc in topics_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "topic_prompt = PromptTemplate(\n",
    "    input_variables=[\"email\", \"sentiment\"],\n",
    "    output_key=\"topics\",\n",
    "    template=f\"\"\"\n",
    "    You are an email classification assistant. Based on the content of the email, please classify it into one or more of the following topics:\n",
    "\n",
    "    {topic_descriptions}\n",
    "\n",
    "    Email content:\n",
    "    {{email}}\n",
    "\n",
    "    Please list the relevant topics based on the email content. If multiple topics apply, separate them with commas. Only return the topic names.\n",
    "    If you do not know the topic, return 'Other'.\n",
    "\n",
    "    Format:\n",
    "    <your topics here>\n",
    "    \"\"\"\n",
    ")\n",
    "topic_chain = LLMChain(llm=llm, prompt=topic_prompt, output_key=\"topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'email': 'I want information on getting a compost bim. I have submitted case number: 9578014.', 'sentiment': 'Neutral', 'topics': 'Trash'}\n"
     ]
    }
   ],
   "source": [
    "# Test the sentiment and topic chains\n",
    "sequential_chain = SequentialChain(\n",
    "    chains=[sentiment_chain, topic_chain],\n",
    "    input_variables=[\"email\"],  # Initial input needed\n",
    "    output_variables=[\"email\", \"sentiment\", \"topics\"]  # Final output of the chain\n",
    ")\n",
    "result_2 = sequential_chain({\"email\": email})\n",
    "print(result_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to format the documents retrieved from the vector store\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Specify the embeddings and directory where the vector store database is located\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "persist_directory = \"../chroma_db\"\n",
    "\n",
    "# Load the saved vectorstore\n",
    "vector_store = Chroma(embedding_function=embedding_function, persist_directory=persist_directory)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the vector_store.\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Use a standard propmt template to perform simple queries on the loaded vectorstore\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# [HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: filler question \\nContext: filler context \\nAnswer:\")]\n",
    "\n",
    "# Instantiate the LLM to use\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=1)\n",
    "\n",
    "# Define the chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the general_response_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the specific_311_topic_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the fun_fact_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
