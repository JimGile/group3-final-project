{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to format the documents retrieved from the vector store\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jim\\AppData\\Local\\Temp\\ipykernel_31936\\3784340789.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
      "C:\\Users\\jim\\AppData\\Local\\Temp\\ipykernel_31936\\3784340789.py:6: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(embedding_function=embedding_function, persist_directory=persist_directory)\n",
      "d:\\Projects\\group3-final-project\\.venv\\Lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "C:\\Users\\jim\\AppData\\Local\\Temp\\ipykernel_31936\\3784340789.py:18: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4\", temperature=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# Specify the embeddings and directory where the vector store database is located\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "persist_directory = \"../chroma_db\"\n",
    "\n",
    "# Load the saved vectorstore\n",
    "vector_store = Chroma(embedding_function=embedding_function, persist_directory=persist_directory)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the vector_store.\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Use a standard propmt template to perform simple queries on the loaded vectorstore\n",
    "# TODO: Need to experiment with different prompt templates\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# [HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: filler question \\nContext: filler context \\nAnswer:\")]\n",
    "\n",
    "# Instantiate the LLM to use\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=1)\n",
    "\n",
    "# Define the chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_template_text = prompt[0].prompt.template\n",
    "standard_template_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distribution of compost bins is done by Solid Waste on a district-by-district basis according to a rollout schedule and District 4, where you reside, is scheduled to receive compost bins in 2025. Unfortunately, these schedules are strict and not alterable. This means that you will not be able to obtain a compost bin until then, despite your request for an earlier delivery.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start asking questions\n",
    "\n",
    "#question = \"\"\"The lack of police presence and code enforcement is sending a growing message that these violations are not important. Second item: affordable denver and wanting more information about how the tax will accomplish the goals set by Mayor.\"\"\"\n",
    "question = \"\"\"I want information on getting a compost bim. I have submitted case number: 9578014.\"\"\"\n",
    "\n",
    "rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4_specific_template_text = \"\"\"\n",
    "You are an assistant for question-answering tasks specifically for generating responses to constituent emails.\n",
    "You work as a senior aide to Councilwoman Diana Romero Campbell, a Denver City Council member for District 4.\n",
    "You represent the South East Region of the city and county of Denver Colorado USA.\n",
    "Use the following pieces of retrieved context to help answer the question and generate a response to the constituent. \n",
    "If you don't know the answer, just say that you don't know but we will get the information and get back to you. \n",
    "Use three to four sentences maximum, keep the answer concise, and be specific to the city and county of Denver.\n",
    "\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you for reaching out. I understand your concerns about acquiring a compost bin. As per the rollout schedule, the Department of Transportation and Infrastructure (DOTI) plans to deliver compost bins to District 4 in 2025. Unfortunately, they have strict procedures we must adhere to and our office is unable to expedite this process. Please know that until compost service starts in your neighborhood, you will continue to receive a credit on your invoice.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with d4_specific_template_text\n",
    "prompt[0].prompt.template = d4_specific_template_text\n",
    "rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYou are an assistant for question-answering tasks specifically for generating responses to constituent emails.\\nYou work as a senior aide to Councilwoman Diana Romero Campbell, a Denver City Council member for District 4.\\nYou represent the South East Region of the city and county of Denver Colorado USA.\\nUse the following pieces of retrieved context to help answer the question and generate a response to the constituent. \\nIf you don't know the answer, just say that you don't know but we will get the information and get back to you. \\nUse three to four sentences maximum, keep the answer concise, and be specific to the city and county of Denver.\\n\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textwrap\n",
    "textwrap.dedent(d4_specific_template_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
